{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4687f4c8",
   "metadata": {},
   "source": [
    "# Wasserstein GAN (WGAN) Implementation\n",
    "\n",
    "This notebook implements a comprehensive Wasserstein GAN with proper critic module and Wasserstein distance optimization. The implementation includes:\n",
    "\n",
    "- **Critic Module**: Replaces the discriminator with a critic that estimates Wasserstein distance\n",
    "- **Wasserstein Loss**: Uses Wasserstein distance instead of binary cross-entropy\n",
    "- **Weight Clipping**: Ensures Lipschitz constraint for the critic\n",
    "- **WGAN-GP**: Optional gradient penalty implementation\n",
    "- **Multi-Dataset Support**: Works with both MNIST and CIFAR10\n",
    "- **Professional Training Pipeline**: Complete training loop with logging and visualization\n",
    "\n",
    "## Key Differences from Standard GAN:\n",
    "1. **Critic vs Discriminator**: The critic outputs a real-valued score rather than a probability\n",
    "2. **Wasserstein Distance**: Measures the cost of transforming one distribution to another\n",
    "3. **No Sigmoid**: Critic output is unbounded\n",
    "4. **Weight Clipping**: Maintains Lipschitz constraint (or gradient penalty in WGAN-GP)\n",
    "5. **Different Training Ratio**: Typically train critic more frequently than generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec521a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "import time\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),  # Console output\n",
    "        logging.FileHandler('wgan_training.log')  # File output\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create logger for WGAN\n",
    "logger = logging.getLogger('WGAN')\n",
    "\n",
    "# Set device globally\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "def get_cuda_device_info():\n",
    "    \"\"\"Get detailed information about CUDA device\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        logger.info(\"=\" * 50)\n",
    "        logger.info(\"CUDA DEVICE INFORMATION\")\n",
    "        logger.info(\"=\" * 50)\n",
    "        \n",
    "        # Basic device info\n",
    "        device_count = torch.cuda.device_count()\n",
    "        current_device = torch.cuda.current_device()\n",
    "        device_name = torch.cuda.get_device_name(current_device)\n",
    "        \n",
    "        logger.info(f\"Number of CUDA devices: {device_count}\")\n",
    "        logger.info(f\"Current device index: {current_device}\")\n",
    "        logger.info(f\"Device name: {device_name}\")\n",
    "        \n",
    "        # Memory information\n",
    "        memory_allocated = torch.cuda.memory_allocated(current_device) / 1024**3  # GB\n",
    "        memory_reserved = torch.cuda.memory_reserved(current_device) / 1024**3    # GB\n",
    "        memory_total = torch.cuda.get_device_properties(current_device).total_memory / 1024**3  # GB\n",
    "        \n",
    "        logger.info(\"MEMORY INFORMATION:\")\n",
    "        logger.info(f\"Total GPU memory: {memory_total:.2f} GB\")\n",
    "        logger.info(f\"Allocated memory: {memory_allocated:.2f} GB\")\n",
    "        logger.info(f\"Reserved memory: {memory_reserved:.2f} GB\")\n",
    "        logger.info(f\"Free memory: {memory_total - memory_allocated:.2f} GB\")\n",
    "        \n",
    "        logger.info(\"=\" * 50)\n",
    "    else:\n",
    "        logger.warning(\"CUDA is not available\")\n",
    "\n",
    "# Call the function to display device info\n",
    "get_cuda_device_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e55c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSetLoader:\n",
    "    def __init__(self, data_dir=\"./data\", batch_size=64):\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.logger = logging.getLogger(f'{__name__}.DataSetLoader')\n",
    "        self.logger.info(f\"DataSetLoader initialized with batch_size={batch_size}, data_dir={data_dir}\")\n",
    "        \n",
    "    def load_mnist(self):\n",
    "        self.logger.info(\"Loading MNIST dataset...\")\n",
    "        \n",
    "        # MNIST transforms - normalized to [-1, 1] range for WGAN\n",
    "        compose = transforms.Compose([\n",
    "            transforms.Resize(64),  # Resize to 64x64 for better quality\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])  # Convert to [-1, 1] range\n",
    "        ])\n",
    "        \n",
    "        # Download and load dataset\n",
    "        out_dir = '{}/dataset'.format(self.data_dir)\n",
    "        self.logger.debug(f\"Loading MNIST from directory: {out_dir}\")\n",
    "        data = datasets.MNIST(root=out_dir, train=True, transform=compose, download=True)\n",
    "        \n",
    "        # Create data loader\n",
    "        data_loader = DataLoader(data, batch_size=self.batch_size, shuffle=True, drop_last=True)\n",
    "        num_batches = len(data_loader)\n",
    "        \n",
    "        # MNIST specifications\n",
    "        img_size = [64, 64]\n",
    "        channels = 1\n",
    "        \n",
    "        self.logger.info(f\"MNIST dataset loaded: {num_batches} batches, image size: {img_size}, channels: {channels}\")\n",
    "        return data_loader, num_batches, img_size, channels\n",
    "    \n",
    "    def load_cifar10(self):\n",
    "        self.logger.info(\"Loading CIFAR10 dataset...\")\n",
    "        \n",
    "        # CIFAR10 transforms - normalized to [-1, 1] range for WGAN\n",
    "        compose = transforms.Compose([\n",
    "            transforms.Resize(64),  # Resize to 64x64 for consistency\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Convert to [-1, 1] range\n",
    "        ])\n",
    "        \n",
    "        # Download and load dataset\n",
    "        out_dir = '{}/dataset'.format(self.data_dir)\n",
    "        self.logger.debug(f\"Loading CIFAR10 from directory: {out_dir}\")\n",
    "        data = datasets.CIFAR10(root=out_dir, train=True, transform=compose, download=True)\n",
    "        \n",
    "        # Create data loader\n",
    "        data_loader = DataLoader(data, batch_size=self.batch_size, shuffle=True, drop_last=True)\n",
    "        num_batches = len(data_loader)\n",
    "        \n",
    "        # CIFAR10 specifications\n",
    "        img_size = [64, 64]\n",
    "        channels = 3\n",
    "        \n",
    "        self.logger.info(f\"CIFAR10 dataset loaded: {num_batches} batches, image size: {img_size}, channels: {channels}\")\n",
    "        return data_loader, num_batches, img_size, channels\n",
    "\n",
    "logger.info(\"DataSetLoader class created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e3ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    \"\"\"\n",
    "    WGAN Critic (replaces Discriminator)\n",
    "    \n",
    "    Key differences from standard discriminator:\n",
    "    1. No sigmoid activation at the end\n",
    "    2. Output is unbounded real value (not probability)\n",
    "    3. Uses Wasserstein distance instead of binary cross-entropy\n",
    "    4. Requires Lipschitz constraint (weight clipping or gradient penalty)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=1, hidden_dim=64, img_size=[64, 64]):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        self.logger = logging.getLogger(f'{__name__}.Critic')\n",
    "        self.img_size = img_size\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        # Calculate final spatial dimensions after convolutions\n",
    "        # Each conv layer with stride=2 reduces size by half\n",
    "        self.final_height = img_size[0] // (2**4)  # 4 conv layers\n",
    "        self.final_width = img_size[1] // (2**4)\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # First layer: in_channels -> hidden_dim\n",
    "            nn.Conv2d(in_channels, hidden_dim, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # Second layer: hidden_dim -> hidden_dim*2\n",
    "            nn.Conv2d(hidden_dim, hidden_dim * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # Third layer: hidden_dim*2 -> hidden_dim*4\n",
    "            nn.Conv2d(hidden_dim * 2, hidden_dim * 4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # Fourth layer: hidden_dim*4 -> hidden_dim*8\n",
    "            nn.Conv2d(hidden_dim * 4, hidden_dim * 8, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Final layer: flatten and output single value (no sigmoid!)\n",
    "        self.final_layer = nn.Sequential(\n",
    "            nn.Conv2d(hidden_dim * 8, 1, kernel_size=self.final_height, stride=1, padding=0, bias=False),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self.logger.info(\"Critic initialized:\")\n",
    "        self.logger.info(f\"  Input channels: {in_channels}\")\n",
    "        self.logger.info(f\"  Hidden dim: {hidden_dim}\")\n",
    "        self.logger.info(f\"  Image size: {img_size}\")\n",
    "        self.logger.info(f\"  Final spatial size: {self.final_height}x{self.final_width}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through critic\n",
    "        \n",
    "        Args:\n",
    "            x: Input images [batch_size, channels, height, width]\n",
    "            \n",
    "        Returns:\n",
    "            Real-valued scores [batch_size] (NOT probabilities)\n",
    "        \"\"\"\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.final_layer(x)\n",
    "        return x.squeeze()  # Remove extra dimensions, return [batch_size]\n",
    "    \n",
    "    def clip_weights(self, clip_value=0.01):\n",
    "        \"\"\"\n",
    "        Clip weights to satisfy Lipschitz constraint\n",
    "        This is the original WGAN approach (WGAN-GP uses gradient penalty instead)\n",
    "        \"\"\"\n",
    "        self.logger.debug(f\"Clipping weights with clip_value={clip_value}\")\n",
    "        for param in self.parameters():\n",
    "            param.data.clamp_(-clip_value, clip_value)\n",
    "\n",
    "# Test the Critic\n",
    "logger.info(\"Testing Critic:\")\n",
    "critic_mnist = Critic(in_channels=1, hidden_dim=64, img_size=[64, 64])\n",
    "test_input = torch.randn(4, 1, 64, 64)\n",
    "output = critic_mnist(test_input)\n",
    "logger.info(f\"Input shape: {test_input.shape}\")\n",
    "logger.info(f\"Output shape: {output.shape}\")\n",
    "logger.debug(f\"Output values: {output}\")\n",
    "logger.info(\"Note: Output values are unbounded (not probabilities)!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed81f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    WGAN Generator\n",
    "    \n",
    "    Generates images from random noise using transposed convolutions.\n",
    "    Output range is [-1, 1] to match data normalization.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim=100, hidden_dim=64, out_channels=1, img_size=[64, 64]):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.logger = logging.getLogger(f'{__name__}.Generator')\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.out_channels = out_channels\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # Calculate starting size (reverse of critic's final size)\n",
    "        self.start_height = img_size[0] // (2**4)  # 4 upsampling layers\n",
    "        self.start_width = img_size[1] // (2**4)\n",
    "        \n",
    "        # Initial projection from latent space to feature maps\n",
    "        self.initial_layer = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, hidden_dim * 8, \n",
    "                             kernel_size=self.start_height, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim * 8),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Upsampling layers\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # First upsampling: hidden_dim*8 -> hidden_dim*4\n",
    "            nn.ConvTranspose2d(hidden_dim * 8, hidden_dim * 4, \n",
    "                             kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim * 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Second upsampling: hidden_dim*4 -> hidden_dim*2\n",
    "            nn.ConvTranspose2d(hidden_dim * 4, hidden_dim * 2, \n",
    "                             kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim * 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Third upsampling: hidden_dim*2 -> hidden_dim\n",
    "            nn.ConvTranspose2d(hidden_dim * 2, hidden_dim, \n",
    "                             kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Final layer: hidden_dim -> out_channels\n",
    "            nn.ConvTranspose2d(hidden_dim, out_channels, \n",
    "                             kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.Tanh()  # Output in [-1, 1] range\n",
    "        )\n",
    "        \n",
    "        self.logger.info(\"Generator initialized:\")\n",
    "        self.logger.info(f\"  Latent dim: {latent_dim}\")\n",
    "        self.logger.info(f\"  Hidden dim: {hidden_dim}\")\n",
    "        self.logger.info(f\"  Output channels: {out_channels}\")\n",
    "        self.logger.info(f\"  Output size: {img_size}\")\n",
    "        self.logger.info(f\"  Starting size: {self.start_height}x{self.start_width}\")\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Forward pass through generator\n",
    "        \n",
    "        Args:\n",
    "            z: Random noise [batch_size, latent_dim, 1, 1]\n",
    "            \n",
    "        Returns:\n",
    "            Generated images [batch_size, out_channels, height, width]\n",
    "        \"\"\"\n",
    "        # If z is 2D, reshape to 4D for conv operations\n",
    "        if len(z.shape) == 2:\n",
    "            z = z.view(z.size(0), z.size(1), 1, 1)\n",
    "        \n",
    "        x = self.initial_layer(z)\n",
    "        x = self.conv_layers(x)\n",
    "        return x\n",
    "\n",
    "def weights_init(m):\n",
    "    \"\"\"\n",
    "    Initialize weights according to DCGAN paper\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "# Test the Generator\n",
    "logger.info(\"Testing Generator:\")\n",
    "generator_mnist = Generator(latent_dim=100, hidden_dim=64, out_channels=1, img_size=[64, 64])\n",
    "generator_mnist.apply(weights_init)\n",
    "\n",
    "# Test with 2D noise (common input format)\n",
    "test_noise_2d = torch.randn(4, 100)\n",
    "output_2d = generator_mnist(test_noise_2d)\n",
    "logger.info(f\"2D Noise shape: {test_noise_2d.shape}\")\n",
    "logger.info(f\"Generated image shape: {output_2d.shape}\")\n",
    "logger.info(f\"Output range: [{output_2d.min():.3f}, {output_2d.max():.3f}]\")\n",
    "\n",
    "# Test with 4D noise\n",
    "test_noise_4d = torch.randn(4, 100, 1, 1)\n",
    "output_4d = generator_mnist(test_noise_4d)\n",
    "logger.info(f\"4D Noise shape: {test_noise_4d.shape}\")\n",
    "logger.info(f\"Generated image shape: {output_4d.shape}\")\n",
    "logger.info(f\"Output range: [{output_4d.min():.3f}, {output_4d.max():.3f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06614f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN:\n",
    "    \"\"\"\n",
    "    Wasserstein GAN Implementation\n",
    "    \n",
    "    Key features:\n",
    "    1. Uses Wasserstein distance instead of binary cross-entropy\n",
    "    2. Critic outputs real-valued scores (not probabilities)\n",
    "    3. Weight clipping to enforce Lipschitz constraint\n",
    "    4. Train critic more frequently than generator (typically 5:1 ratio)\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim=100, img_size=[64, 64], channels=1, \n",
    "                 hidden_dim=64, batch_size=64, lr=5e-5, device=None,\n",
    "                 clip_value=0.01, critic_iterations=5):\n",
    "        \n",
    "        self.logger = logging.getLogger(f'{__name__}.WGAN')\n",
    "        \n",
    "        # Set device\n",
    "        self.device = device if device else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.logger.info(f\"WGAN initialized on device: {self.device}\")\n",
    "        \n",
    "        # Model parameters\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_size = img_size\n",
    "        self.channels = channels\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.clip_value = clip_value\n",
    "        self.critic_iterations = critic_iterations\n",
    "        \n",
    "        # Initialize networks\n",
    "        self.generator = Generator(\n",
    "            latent_dim=latent_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            out_channels=channels,\n",
    "            img_size=img_size\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.critic = Critic(\n",
    "            in_channels=channels,\n",
    "            hidden_dim=hidden_dim,\n",
    "            img_size=img_size\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.generator.apply(weights_init)\n",
    "        self.critic.apply(weights_init)\n",
    "        self.logger.debug(\"Applied weight initialization to Generator and Critic\")\n",
    "        \n",
    "        # Optimizers (RMSprop is recommended for WGAN)\n",
    "        self.g_optimizer = optim.RMSprop(self.generator.parameters(), lr=lr)\n",
    "        self.c_optimizer = optim.RMSprop(self.critic.parameters(), lr=lr)\n",
    "        \n",
    "        # For visualization\n",
    "        self.fixed_noise = torch.randn(16, latent_dim, device=self.device)\n",
    "        \n",
    "        self.logger.info(\"WGAN Architecture:\")\n",
    "        self.logger.info(f\"  Generator parameters: {sum(p.numel() for p in self.generator.parameters()):,}\")\n",
    "        self.logger.info(f\"  Critic parameters: {sum(p.numel() for p in self.critic.parameters()):,}\")\n",
    "        self.logger.info(f\"  Critic iterations per generator step: {critic_iterations}\")\n",
    "        self.logger.info(f\"  Weight clip value: {clip_value}\")\n",
    "    \n",
    "    def generate_noise(self, batch_size=None):\n",
    "        \"\"\"Generate random noise for generator\"\"\"\n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "        return torch.randn(batch_size, self.latent_dim, device=self.device)\n",
    "    \n",
    "    def train_critic(self, real_images):\n",
    "        \"\"\"\n",
    "        Train critic for one step\n",
    "        \n",
    "        WGAN Critic Loss: E[C(real)] - E[C(fake)]\n",
    "        We want to maximize this (maximize distance between real and fake)\n",
    "        So we minimize: -E[C(real)] + E[C(fake)]\n",
    "        \"\"\"\n",
    "        batch_size = real_images.size(0)\n",
    "        real_images = real_images.to(self.device)\n",
    "        \n",
    "        # Reset gradients\n",
    "        self.c_optimizer.zero_grad()\n",
    "        \n",
    "        # Train on real images\n",
    "        real_scores = self.critic(real_images)\n",
    "        real_loss = -torch.mean(real_scores)  # Negative because we want to maximize\n",
    "        \n",
    "        # Train on fake images\n",
    "        noise = self.generate_noise(batch_size)\n",
    "        fake_images = self.generator(noise).detach()  # Detach to avoid training generator\n",
    "        fake_scores = self.critic(fake_images)\n",
    "        fake_loss = torch.mean(fake_scores)\n",
    "        \n",
    "        # Total critic loss\n",
    "        critic_loss = real_loss + fake_loss\n",
    "        critic_loss.backward()\n",
    "        \n",
    "        # Update critic\n",
    "        self.c_optimizer.step()\n",
    "        \n",
    "        # Clip weights to enforce Lipschitz constraint\n",
    "        self.critic.clip_weights(self.clip_value)\n",
    "        \n",
    "        return {\n",
    "            'critic_loss': critic_loss.item(),\n",
    "            'real_loss': real_loss.item(),\n",
    "            'fake_loss': fake_loss.item(),\n",
    "            'real_score': real_scores.mean().item(),\n",
    "            'fake_score': fake_scores.mean().item(),\n",
    "            'wasserstein_distance': -(real_scores.mean() - fake_scores.mean()).item()\n",
    "        }\n",
    "    \n",
    "    def train_generator(self):\n",
    "        \"\"\"\n",
    "        Train generator for one step\n",
    "        \n",
    "        WGAN Generator Loss: -E[C(G(z))]\n",
    "        We want to maximize E[C(G(z))] (make fake images get high scores)\n",
    "        So we minimize: -E[C(G(z))]\n",
    "        \"\"\"\n",
    "        # Reset gradients\n",
    "        self.g_optimizer.zero_grad()\n",
    "        \n",
    "        # Generate fake images\n",
    "        noise = self.generate_noise()\n",
    "        fake_images = self.generator(noise)\n",
    "        fake_scores = self.critic(fake_images)\n",
    "        \n",
    "        # Generator loss: we want to maximize fake scores\n",
    "        generator_loss = -torch.mean(fake_scores)\n",
    "        generator_loss.backward()\n",
    "        \n",
    "        # Update generator\n",
    "        self.g_optimizer.step()\n",
    "        \n",
    "        return {\n",
    "            'generator_loss': generator_loss.item(),\n",
    "            'fake_score': fake_scores.mean().item()\n",
    "        }\n",
    "    \n",
    "    def train_step(self, real_images):\n",
    "        \"\"\"\n",
    "        Complete training step: train critic multiple times, then generator once\n",
    "        \"\"\"\n",
    "        metrics = {\n",
    "            'critic_losses': [],\n",
    "            'wasserstein_distances': [],\n",
    "            'real_scores': [],\n",
    "            'fake_scores': []\n",
    "        }\n",
    "        \n",
    "        # Train critic multiple times\n",
    "        for _ in range(self.critic_iterations):\n",
    "            critic_metrics = self.train_critic(real_images)\n",
    "            metrics['critic_losses'].append(critic_metrics['critic_loss'])\n",
    "            metrics['wasserstein_distances'].append(critic_metrics['wasserstein_distance'])\n",
    "            metrics['real_scores'].append(critic_metrics['real_score'])\n",
    "            metrics['fake_scores'].append(critic_metrics['fake_score'])\n",
    "        \n",
    "        # Train generator once\n",
    "        generator_metrics = self.train_generator()\n",
    "        \n",
    "        # Return averaged metrics\n",
    "        return {\n",
    "            'critic_loss': np.mean(metrics['critic_losses']),\n",
    "            'generator_loss': generator_metrics['generator_loss'],\n",
    "            'wasserstein_distance': np.mean(metrics['wasserstein_distances']),\n",
    "            'real_score': np.mean(metrics['real_scores']),\n",
    "            'fake_score': np.mean(metrics['fake_scores'])\n",
    "        }\n",
    "    \n",
    "    def generate_samples(self, num_samples=16, noise=None):\n",
    "        \"\"\"Generate sample images\"\"\"\n",
    "        with torch.no_grad():\n",
    "            if noise is None:\n",
    "                noise = self.generate_noise(num_samples)\n",
    "            else:\n",
    "                noise = noise.to(self.device)\n",
    "            \n",
    "            self.generator.eval()\n",
    "            samples = self.generator(noise)\n",
    "            self.generator.train()\n",
    "            \n",
    "            return samples.cpu()\n",
    "    \n",
    "    def save_models(self, path_prefix):\n",
    "        \"\"\"Save generator and critic models\"\"\"\n",
    "        torch.save({\n",
    "            'generator_state_dict': self.generator.state_dict(),\n",
    "            'critic_state_dict': self.critic.state_dict(),\n",
    "            'g_optimizer_state_dict': self.g_optimizer.state_dict(),\n",
    "            'c_optimizer_state_dict': self.c_optimizer.state_dict(),\n",
    "            'config': {\n",
    "                'latent_dim': self.latent_dim,\n",
    "                'img_size': self.img_size,\n",
    "                'channels': self.channels,\n",
    "                'batch_size': self.batch_size,\n",
    "                'lr': self.lr,\n",
    "                'clip_value': self.clip_value,\n",
    "                'critic_iterations': self.critic_iterations\n",
    "            }\n",
    "        }, f\"{path_prefix}_wgan.pth\")\n",
    "        self.logger.info(f\"Models saved to {path_prefix}_wgan.pth\")\n",
    "    \n",
    "    def load_models(self, path):\n",
    "        \"\"\"Load generator and critic models\"\"\"\n",
    "        self.logger.info(f\"Loading models from {path}\")\n",
    "        checkpoint = torch.load(path, map_location=self.device)\n",
    "        self.generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "        self.critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "        self.g_optimizer.load_state_dict(checkpoint['g_optimizer_state_dict'])\n",
    "        self.c_optimizer.load_state_dict(checkpoint['c_optimizer_state_dict'])\n",
    "        self.logger.info(f\"Models loaded successfully from {path}\")\n",
    "\n",
    "logger.info(\"WGAN class created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb108c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGANLogger:\n",
    "    \"\"\"\n",
    "    Logger for WGAN training (similar to gan_utils.py Logger)\n",
    "    \n",
    "    Provides logging, visualization, and model saving functionality\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name, data_name, save_dir=\"./data\"):\n",
    "        self.model_name = model_name\n",
    "        self.data_name = data_name\n",
    "        self.save_dir = save_dir\n",
    "        self.logger = logging.getLogger(f'{__name__}.WGANLogger')\n",
    "        \n",
    "        self.comment = '{}_{}'.format(model_name, data_name)\n",
    "        self.data_subdir = '{}/{}'.format(model_name, data_name)\n",
    "        \n",
    "        # Create directories\n",
    "        self.images_dir = f'{save_dir}/images/{self.data_subdir}'\n",
    "        self.models_dir = f'{save_dir}/models/{self.data_subdir}'\n",
    "        self._make_dir(self.images_dir)\n",
    "        self._make_dir(self.models_dir)\n",
    "        \n",
    "        # Training metrics storage\n",
    "        self.metrics_history = defaultdict(list)\n",
    "        \n",
    "        self.logger.info(\"WGANLogger initialized:\")\n",
    "        self.logger.info(f\"  Model: {model_name}\")\n",
    "        self.logger.info(f\"  Dataset: {data_name}\")\n",
    "        self.logger.info(f\"  Save directory: {save_dir}\")\n",
    "    \n",
    "    def log_metrics(self, metrics, epoch, batch_idx):\n",
    "        \"\"\"Log training metrics\"\"\"\n",
    "        # Store metrics\n",
    "        for key, value in metrics.items():\n",
    "            self.metrics_history[key].append(value)\n",
    "        \n",
    "        # Log progress\n",
    "        if batch_idx % 50 == 0:\n",
    "            self.logger.info(f\"Epoch [{epoch}] Batch [{batch_idx}] \"\n",
    "                           f\"C_loss: {metrics.get('critic_loss', 0):.4f} \"\n",
    "                           f\"G_loss: {metrics.get('generator_loss', 0):.4f} \"\n",
    "                           f\"W_dist: {metrics.get('wasserstein_distance', 0):.4f}\")\n",
    "    \n",
    "    def log_images(self, wgan, epoch, batch_idx, num_images=16):\n",
    "        \"\"\"\n",
    "        Generate and save sample images\n",
    "        \n",
    "        Args:\n",
    "            wgan: WGAN model instance\n",
    "            epoch: Current epoch\n",
    "            batch_idx: Current batch index\n",
    "            num_images: Number of images to generate\n",
    "        \"\"\"\n",
    "        # Generate samples\n",
    "        samples = wgan.generate_samples(num_images, wgan.fixed_noise[:num_images])\n",
    "        \n",
    "        # Create grid\n",
    "        nrows = int(np.sqrt(num_images))\n",
    "        fig, axes = plt.subplots(nrows, nrows, figsize=(8, 8))\n",
    "        \n",
    "        for i in range(num_images):\n",
    "            row, col = i // nrows, i % nrows\n",
    "            \n",
    "            # Get sample and convert to numpy\n",
    "            sample = samples[i].numpy()\n",
    "            \n",
    "            # Handle different channel configurations\n",
    "            if sample.shape[0] == 1:  # Grayscale\n",
    "                img = sample.squeeze(0)  # Remove channel dimension\n",
    "                axes[row, col].imshow(img, cmap='gray', vmin=-1, vmax=1)\n",
    "            elif sample.shape[0] == 3:  # RGB\n",
    "                img = sample.transpose(1, 2, 0)  # Convert to (H, W, C)\n",
    "                # Denormalize from [-1, 1] to [0, 1]\n",
    "                img = (img + 1) / 2\n",
    "                axes[row, col].imshow(np.clip(img, 0, 1))\n",
    "            \n",
    "            axes[row, col].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save image\n",
    "        filename = f'{self.images_dir}/epoch_{epoch}_batch_{batch_idx}.png'\n",
    "        plt.savefig(filename, bbox_inches='tight', dpi=150)\n",
    "        \n",
    "        # Display if in notebook\n",
    "        if batch_idx % 200 == 0:  # Show every 200 batches\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "    \n",
    "    def display_status(self, epoch, num_epochs, batch_idx, num_batches, metrics):\n",
    "        \"\"\"Display training status\"\"\"\n",
    "        progress = (batch_idx / num_batches) * 100\n",
    "        \n",
    "        self.logger.info(f'Epoch: [{epoch}/{num_epochs}] '\n",
    "                        f'Batch: [{batch_idx}/{num_batches}] '\n",
    "                        f'({progress:.1f}%)')\n",
    "        self.logger.info(f'Critic Loss: {metrics.get(\"critic_loss\", 0):.4f}')\n",
    "        self.logger.info(f'Generator Loss: {metrics.get(\"generator_loss\", 0):.4f}')\n",
    "        self.logger.info(f'Wasserstein Distance: {metrics.get(\"wasserstein_distance\", 0):.4f}')\n",
    "        self.logger.info(f'Real Score: {metrics.get(\"real_score\", 0):.4f}')\n",
    "        self.logger.info(f'Fake Score: {metrics.get(\"fake_score\", 0):.4f}')\n",
    "    \n",
    "    def save_models(self, wgan, epoch):\n",
    "        \"\"\"Save WGAN models\"\"\"\n",
    "        filename = f'{self.models_dir}/wgan_epoch_{epoch}.pth'\n",
    "        wgan.save_models(filename.replace('.pth', ''))\n",
    "    \n",
    "    def plot_training_progress(self):\n",
    "        \"\"\"Plot training metrics over time\"\"\"\n",
    "        if not self.metrics_history:\n",
    "            self.logger.warning(\"No metrics to plot yet\")\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        \n",
    "        # Plot critic loss\n",
    "        if 'critic_loss' in self.metrics_history:\n",
    "            axes[0, 0].plot(self.metrics_history['critic_loss'])\n",
    "            axes[0, 0].set_title('Critic Loss')\n",
    "            axes[0, 0].set_xlabel('Iteration')\n",
    "            axes[0, 0].set_ylabel('Loss')\n",
    "        \n",
    "        # Plot generator loss\n",
    "        if 'generator_loss' in self.metrics_history:\n",
    "            axes[0, 1].plot(self.metrics_history['generator_loss'])\n",
    "            axes[0, 1].set_title('Generator Loss')\n",
    "            axes[0, 1].set_xlabel('Iteration')\n",
    "            axes[0, 1].set_ylabel('Loss')\n",
    "        \n",
    "        # Plot Wasserstein distance\n",
    "        if 'wasserstein_distance' in self.metrics_history:\n",
    "            axes[1, 0].plot(self.metrics_history['wasserstein_distance'])\n",
    "            axes[1, 0].set_title('Wasserstein Distance')\n",
    "            axes[1, 0].set_xlabel('Iteration')\n",
    "            axes[1, 0].set_ylabel('Distance')\n",
    "        \n",
    "        # Plot real vs fake scores\n",
    "        if 'real_score' in self.metrics_history and 'fake_score' in self.metrics_history:\n",
    "            axes[1, 1].plot(self.metrics_history['real_score'], label='Real Score')\n",
    "            axes[1, 1].plot(self.metrics_history['fake_score'], label='Fake Score')\n",
    "            axes[1, 1].set_title('Critic Scores')\n",
    "            axes[1, 1].set_xlabel('Iteration')\n",
    "            axes[1, 1].set_ylabel('Score')\n",
    "            axes[1, 1].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def generate_final_samples(self, wgan, num_samples=64):\n",
    "        \"\"\"Generate a large grid of final samples\"\"\"\n",
    "        samples = wgan.generate_samples(num_samples)\n",
    "        \n",
    "        nrows = int(np.sqrt(num_samples))\n",
    "        fig, axes = plt.subplots(nrows, nrows, figsize=(12, 12))\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            row, col = i // nrows, i % nrows\n",
    "            \n",
    "            sample = samples[i].numpy()\n",
    "            \n",
    "            if sample.shape[0] == 1:  # Grayscale\n",
    "                img = sample.squeeze(0)\n",
    "                axes[row, col].imshow(img, cmap='gray', vmin=-1, vmax=1)\n",
    "            elif sample.shape[0] == 3:  # RGB\n",
    "                img = sample.transpose(1, 2, 0)\n",
    "                img = (img + 1) / 2\n",
    "                axes[row, col].imshow(np.clip(img, 0, 1))\n",
    "            \n",
    "            axes[row, col].axis('off')\n",
    "        \n",
    "        plt.suptitle(f'Final Generated Samples - {self.comment}', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save final samples\n",
    "        filename = f'{self.images_dir}/final_samples.png'\n",
    "        plt.savefig(filename, bbox_inches='tight', dpi=200)\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def _make_dir(directory):\n",
    "        \"\"\"Create directory if it doesn't exist\"\"\"\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "logger.info(\"WGANLogger class created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a5d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "def train_wgan(wgan, dataloader, wgan_logger, num_epochs=25, save_every=5):\n",
    "    \"\"\"\n",
    "    Train WGAN with proper logging and visualization\n",
    "    \n",
    "    Args:\n",
    "        wgan: WGAN model instance\n",
    "        dataloader: Training data loader\n",
    "        wgan_logger: WGANLogger instance\n",
    "        num_epochs: Number of training epochs\n",
    "        save_every: Save models every N epochs\n",
    "    \"\"\"\n",
    "    train_logger = logging.getLogger('WGAN.Training')\n",
    "    train_logger.info(f\"Starting WGAN training for {num_epochs} epochs...\")\n",
    "    train_logger.info(\"=\"*80)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        for batch_idx, (real_images, _) in enumerate(dataloader):\n",
    "            # Train WGAN\n",
    "            metrics = wgan.train_step(real_images)\n",
    "            \n",
    "            # Log metrics\n",
    "            wgan_logger.log_metrics(metrics, epoch, batch_idx)\n",
    "            \n",
    "            # Generate and save images periodically\n",
    "            if batch_idx % 100 == 0:\n",
    "                wgan_logger.log_images(wgan, epoch, batch_idx)\n",
    "            \n",
    "            # Display detailed status periodically\n",
    "            if batch_idx % 200 == 0:\n",
    "                wgan_logger.display_status(epoch, num_epochs, batch_idx, len(dataloader), metrics)\n",
    "        \n",
    "        # End of epoch summary\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        train_logger.info(f\"Epoch [{epoch}/{num_epochs}] completed in {epoch_time:.2f}s\")\n",
    "        \n",
    "        # Save models periodically\n",
    "        if (epoch + 1) % save_every == 0:\n",
    "            wgan_logger.save_models(wgan, epoch)\n",
    "        \n",
    "        # Plot progress periodically\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            wgan_logger.plot_training_progress()\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    train_logger.info(f\"Training completed in {total_time/60:.2f} minutes!\")\n",
    "    \n",
    "    # Generate final samples\n",
    "    wgan_logger.generate_final_samples(wgan, num_samples=64)\n",
    "    \n",
    "    return wgan_logger\n",
    "\n",
    "logger.info(\"Training function created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ceded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Training Example\n",
    "mnist_logger = logging.getLogger('WGAN.MNIST_Example')\n",
    "mnist_logger.info(\"=\"*80)\n",
    "mnist_logger.info(\"WGAN TRAINING ON MNIST DATASET\")\n",
    "mnist_logger.info(\"=\"*80)\n",
    "\n",
    "# Initialize dataset loader\n",
    "dataset_loader = DataSetLoader(batch_size=64, data_dir='./data')\n",
    "\n",
    "# Load MNIST data\n",
    "mnist_dataloader, num_batches, img_size, channels = dataset_loader.load_mnist()\n",
    "mnist_logger.info(f\"MNIST - Batches: {num_batches}, Image size: {img_size}, Channels: {channels}\")\n",
    "\n",
    "# Create WGAN for MNIST\n",
    "wgan_mnist = WGAN(\n",
    "    latent_dim=100,\n",
    "    img_size=img_size,\n",
    "    channels=channels,\n",
    "    hidden_dim=64,\n",
    "    batch_size=64,\n",
    "    lr=5e-5,  # Lower learning rate for WGAN\n",
    "    device=device,\n",
    "    clip_value=0.01,\n",
    "    critic_iterations=5\n",
    ")\n",
    "\n",
    "mnist_logger.info(\"WGAN MNIST Configuration:\")\n",
    "mnist_logger.info(f\"  Latent dimension: {wgan_mnist.latent_dim}\")\n",
    "mnist_logger.info(f\"  Image size: {wgan_mnist.img_size}\")\n",
    "mnist_logger.info(f\"  Channels: {wgan_mnist.channels}\")\n",
    "mnist_logger.info(f\"  Learning rate: {wgan_mnist.lr}\")\n",
    "mnist_logger.info(f\"  Clip value: {wgan_mnist.clip_value}\")\n",
    "mnist_logger.info(f\"  Critic iterations: {wgan_mnist.critic_iterations}\")\n",
    "\n",
    "# Create logger\n",
    "logger_mnist = WGANLogger(\"WGAN\", \"MNIST\", save_dir=\"./data\")\n",
    "\n",
    "# Generate initial samples (before training)\n",
    "mnist_logger.info(\"Generating initial samples (before training)...\")\n",
    "initial_samples = wgan_mnist.generate_samples(16)\n",
    "fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
    "for i in range(16):\n",
    "    row, col = i // 4, i % 4\n",
    "    img = initial_samples[i, 0].numpy()\n",
    "    axes[row, col].imshow(img, cmap='gray', vmin=-1, vmax=1)\n",
    "    axes[row, col].axis('off')\n",
    "plt.suptitle('Initial Generated Samples (Before Training)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Train WGAN on MNIST (start with fewer epochs for demonstration)\n",
    "mnist_logger.info(\"Starting MNIST training...\")\n",
    "logger_mnist = train_wgan(\n",
    "    wgan=wgan_mnist,\n",
    "    dataloader=mnist_dataloader,\n",
    "    wgan_logger=logger_mnist,\n",
    "    num_epochs=10,  # Start with 10 epochs for quick demo\n",
    "    save_every=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3019282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10 Training Example\n",
    "cifar_logger = logging.getLogger('WGAN.CIFAR10_Example')\n",
    "cifar_logger.info(\"=\"*80)\n",
    "cifar_logger.info(\"WGAN TRAINING ON CIFAR10 DATASET\")\n",
    "cifar_logger.info(\"=\"*80)\n",
    "\n",
    "# Load CIFAR10 data\n",
    "cifar_dataloader, num_batches, img_size, channels = dataset_loader.load_cifar10()\n",
    "cifar_logger.info(f\"CIFAR10 - Batches: {num_batches}, Image size: {img_size}, Channels: {channels}\")\n",
    "\n",
    "# Create WGAN for CIFAR10\n",
    "wgan_cifar = WGAN(\n",
    "    latent_dim=100,\n",
    "    img_size=img_size,\n",
    "    channels=channels,\n",
    "    hidden_dim=64,\n",
    "    batch_size=64,\n",
    "    lr=5e-5,  # Lower learning rate for WGAN\n",
    "    device=device,\n",
    "    clip_value=0.01,\n",
    "    critic_iterations=5\n",
    ")\n",
    "\n",
    "cifar_logger.info(\"WGAN CIFAR10 Configuration:\")\n",
    "cifar_logger.info(f\"  Latent dimension: {wgan_cifar.latent_dim}\")\n",
    "cifar_logger.info(f\"  Image size: {wgan_cifar.img_size}\")\n",
    "cifar_logger.info(f\"  Channels: {wgan_cifar.channels}\")\n",
    "cifar_logger.info(f\"  Learning rate: {wgan_cifar.lr}\")\n",
    "cifar_logger.info(f\"  Clip value: {wgan_cifar.clip_value}\")\n",
    "cifar_logger.info(f\"  Critic iterations: {wgan_cifar.critic_iterations}\")\n",
    "\n",
    "# Create logger\n",
    "logger_cifar = WGANLogger(\"WGAN\", \"CIFAR10\", save_dir=\"./data\")\n",
    "\n",
    "# Generate initial samples (before training)\n",
    "cifar_logger.info(\"Generating initial samples (before training)...\")\n",
    "initial_samples_cifar = wgan_cifar.generate_samples(16)\n",
    "fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
    "for i in range(16):\n",
    "    row, col = i // 4, i % 4\n",
    "    img = initial_samples_cifar[i].numpy().transpose(1, 2, 0)\n",
    "    img = (img + 1) / 2  # Denormalize to [0, 1]\n",
    "    axes[row, col].imshow(np.clip(img, 0, 1))\n",
    "    axes[row, col].axis('off')\n",
    "plt.suptitle('Initial Generated Samples (Before Training) - CIFAR10', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Train WGAN on CIFAR10 (start with fewer epochs for demonstration)\n",
    "cifar_logger.info(\"Starting CIFAR10 training...\")\n",
    "logger_cifar = train_wgan(\n",
    "    wgan=wgan_cifar,\n",
    "    dataloader=cifar_dataloader,\n",
    "    wgan_logger=logger_cifar,\n",
    "    num_epochs=10,  # Start with 10 epochs for quick demo\n",
    "    save_every=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e47d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WGAN-GP (Gradient Penalty) Implementation\n",
    "class WGAN_GP(WGAN):\n",
    "    \"\"\"\n",
    "    WGAN with Gradient Penalty\n",
    "    \n",
    "    Replaces weight clipping with gradient penalty for better stability\n",
    "    and improved training dynamics.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim=100, img_size=[64, 64], channels=1, \n",
    "                 hidden_dim=64, batch_size=64, lr=1e-4, device=None,\n",
    "                 lambda_gp=10, critic_iterations=5):\n",
    "        \n",
    "        # Initialize parent class (but don't use clip_value)\n",
    "        super().__init__(\n",
    "            latent_dim=latent_dim,\n",
    "            img_size=img_size,\n",
    "            channels=channels,\n",
    "            hidden_dim=hidden_dim,\n",
    "            batch_size=batch_size,\n",
    "            lr=lr,\n",
    "            device=device,\n",
    "            clip_value=None,  # Not used in WGAN-GP\n",
    "            critic_iterations=critic_iterations\n",
    "        )\n",
    "        \n",
    "        self.lambda_gp = lambda_gp\n",
    "        \n",
    "        # Use Adam optimizer for WGAN-GP (works better than RMSprop)\n",
    "        self.g_optimizer = optim.Adam(self.generator.parameters(), lr=lr, betas=(0.0, 0.9))\n",
    "        self.c_optimizer = optim.Adam(self.critic.parameters(), lr=lr, betas=(0.0, 0.9))\n",
    "        \n",
    "        self.logger.info(f\"WGAN-GP initialized with gradient penalty lambda: {lambda_gp}\")\n",
    "    \n",
    "    def gradient_penalty(self, real_images, fake_images):\n",
    "        \"\"\"\n",
    "        Calculate gradient penalty for WGAN-GP\n",
    "        \n",
    "        Args:\n",
    "            real_images: Real images from dataset\n",
    "            fake_images: Generated fake images\n",
    "            \n",
    "        Returns:\n",
    "            Gradient penalty term\n",
    "        \"\"\"\n",
    "        batch_size = real_images.size(0)\n",
    "        \n",
    "        # Random weight term for interpolation\n",
    "        alpha = torch.rand(batch_size, 1, 1, 1, device=self.device)\n",
    "        \n",
    "        # Get interpolated images\n",
    "        interpolated = alpha * real_images + (1 - alpha) * fake_images\n",
    "        interpolated.requires_grad_(True)\n",
    "        \n",
    "        # Get critic scores for interpolated images\n",
    "        interpolated_scores = self.critic(interpolated)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=interpolated_scores,\n",
    "            inputs=interpolated,\n",
    "            grad_outputs=torch.ones_like(interpolated_scores),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True\n",
    "        )[0]\n",
    "        \n",
    "        # Calculate gradient penalty\n",
    "        gradients = gradients.view(batch_size, -1)\n",
    "        gradient_norm = gradients.norm(2, dim=1)\n",
    "        gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "        \n",
    "        return gradient_penalty\n",
    "    \n",
    "    def train_critic(self, real_images):\n",
    "        \"\"\"\n",
    "        Train critic with gradient penalty instead of weight clipping\n",
    "        \"\"\"\n",
    "        batch_size = real_images.size(0)\n",
    "        real_images = real_images.to(self.device)\n",
    "        \n",
    "        # Reset gradients\n",
    "        self.c_optimizer.zero_grad()\n",
    "        \n",
    "        # Train on real images\n",
    "        real_scores = self.critic(real_images)\n",
    "        real_loss = -torch.mean(real_scores)\n",
    "        \n",
    "        # Train on fake images\n",
    "        noise = self.generate_noise(batch_size)\n",
    "        fake_images = self.generator(noise).detach()\n",
    "        fake_scores = self.critic(fake_images)\n",
    "        fake_loss = torch.mean(fake_scores)\n",
    "        \n",
    "        # Calculate gradient penalty\n",
    "        gp = self.gradient_penalty(real_images, fake_images)\n",
    "        \n",
    "        # Total critic loss\n",
    "        critic_loss = real_loss + fake_loss + self.lambda_gp * gp\n",
    "        critic_loss.backward()\n",
    "        \n",
    "        # Update critic (no weight clipping needed!)\n",
    "        self.c_optimizer.step()\n",
    "        \n",
    "        return {\n",
    "            'critic_loss': critic_loss.item(),\n",
    "            'real_loss': real_loss.item(),\n",
    "            'fake_loss': fake_loss.item(),\n",
    "            'gradient_penalty': gp.item(),\n",
    "            'real_score': real_scores.mean().item(),\n",
    "            'fake_score': fake_scores.mean().item(),\n",
    "            'wasserstein_distance': -(real_scores.mean() - fake_scores.mean()).item()\n",
    "        }\n",
    "\n",
    "# Extended Training Examples and Utilities\n",
    "utils_logger = logging.getLogger('WGAN.Utilities')\n",
    "utils_logger.info(\"=\"*80)\n",
    "utils_logger.info(\"EXTENDED TRAINING EXAMPLES AND UTILITIES\")\n",
    "utils_logger.info(\"=\"*80)\n",
    "\n",
    "def compare_wgan_vs_wgan_gp(dataset_name=\"mnist\", num_epochs=15):\n",
    "    \"\"\"\n",
    "    Compare WGAN vs WGAN-GP on the same dataset\n",
    "    \"\"\"\n",
    "    compare_logger = logging.getLogger('WGAN.Comparison')\n",
    "    compare_logger.info(f\"Comparing WGAN vs WGAN-GP on {dataset_name.upper()}...\")\n",
    "    \n",
    "    # Load dataset\n",
    "    if dataset_name.lower() == \"mnist\":\n",
    "        dataloader, _, img_size, channels = dataset_loader.load_mnist()\n",
    "    else:\n",
    "        dataloader, _, img_size, channels = dataset_loader.load_cifar10()\n",
    "    \n",
    "    # Create both models\n",
    "    wgan_original = WGAN(\n",
    "        latent_dim=100, img_size=img_size, channels=channels,\n",
    "        hidden_dim=64, batch_size=64, lr=5e-5, device=device,\n",
    "        clip_value=0.01, critic_iterations=5\n",
    "    )\n",
    "    \n",
    "    wgan_gp = WGAN_GP(\n",
    "        latent_dim=100, img_size=img_size, channels=channels,\n",
    "        hidden_dim=64, batch_size=64, lr=1e-4, device=device,\n",
    "        lambda_gp=10, critic_iterations=5\n",
    "    )\n",
    "    \n",
    "    # Create loggers\n",
    "    logger_original = WGANLogger(\"WGAN_Original\", dataset_name.upper())\n",
    "    logger_gp = WGANLogger(\"WGAN_GP\", dataset_name.upper())\n",
    "    \n",
    "    compare_logger.info(\"Training original WGAN...\")\n",
    "    train_wgan(wgan_original, dataloader, logger_original, num_epochs=num_epochs//2, save_every=5)\n",
    "    \n",
    "    compare_logger.info(\"Training WGAN-GP...\")\n",
    "    train_wgan(wgan_gp, dataloader, logger_gp, num_epochs=num_epochs//2, save_every=5)\n",
    "    \n",
    "    # Compare results\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Compare losses\n",
    "    axes[0, 0].plot(logger_original.metrics_history['critic_loss'], label='WGAN', alpha=0.7)\n",
    "    axes[0, 0].plot(logger_gp.metrics_history['critic_loss'], label='WGAN-GP', alpha=0.7)\n",
    "    axes[0, 0].set_title('Critic Loss Comparison')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    axes[0, 1].plot(logger_original.metrics_history['generator_loss'], label='WGAN', alpha=0.7)\n",
    "    axes[0, 1].plot(logger_gp.metrics_history['generator_loss'], label='WGAN-GP', alpha=0.7)\n",
    "    axes[0, 1].set_title('Generator Loss Comparison')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Compare Wasserstein distances\n",
    "    axes[1, 0].plot(logger_original.metrics_history['wasserstein_distance'], label='WGAN', alpha=0.7)\n",
    "    axes[1, 0].plot(logger_gp.metrics_history['wasserstein_distance'], label='WGAN-GP', alpha=0.7)\n",
    "    axes[1, 0].set_title('Wasserstein Distance Comparison')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Compare sample quality (show final samples)\n",
    "    axes[1, 1].axis('off')\n",
    "    axes[1, 1].text(0.5, 0.5, f'Check generated samples\\\\nfrom both models above', \n",
    "                   ha='center', va='center', fontsize=12)\n",
    "    \n",
    "    plt.suptitle(f'WGAN vs WGAN-GP Comparison on {dataset_name.upper()}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage instructions\n",
    "usage_info = \"\"\"\n",
    "USAGE EXAMPLES:\n",
    "\n",
    "1. Quick WGAN training (already done above):\n",
    "   - MNIST and CIFAR10 models trained for 10 epochs each\n",
    "\n",
    "2. Extended training:\n",
    "   train_wgan(wgan_mnist, mnist_dataloader, logger_mnist, num_epochs=50, save_every=10)\n",
    "\n",
    "3. WGAN-GP training:\n",
    "   wgan_gp = WGAN_GP(latent_dim=100, img_size=[64,64], channels=1, lambda_gp=10)\n",
    "   logger_gp = WGANLogger(\"WGAN_GP\", \"MNIST\")\n",
    "   train_wgan(wgan_gp, mnist_dataloader, logger_gp, num_epochs=25)\n",
    "\n",
    "4. Compare WGAN vs WGAN-GP:\n",
    "   compare_wgan_vs_wgan_gp(\"mnist\", num_epochs=20)\n",
    "   compare_wgan_vs_wgan_gp(\"cifar10\", num_epochs=20)\n",
    "\n",
    "5. Load saved models:\n",
    "   wgan_mnist.load_models(\"./data/models/WGAN/MNIST/wgan_epoch_9_wgan.pth\")\n",
    "\n",
    "6. Generate new samples:\n",
    "   samples = wgan_mnist.generate_samples(64)\n",
    "   # Display samples...\n",
    "\n",
    "KEY FEATURES IMPLEMENTED:\n",
    " Proper Wasserstein distance calculation\n",
    " Critic instead of discriminator (no sigmoid)\n",
    " Weight clipping for Lipschitz constraint\n",
    " WGAN-GP with gradient penalty\n",
    " Professional training pipeline with structured logging\n",
    " Comprehensive logging and visualization\n",
    " Support for both MNIST and CIFAR10\n",
    " Model saving and loading\n",
    " Training progress visualization\n",
    " File and console logging with timestamps\n",
    "\"\"\"\n",
    "\n",
    "utils_logger.info(usage_info)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
