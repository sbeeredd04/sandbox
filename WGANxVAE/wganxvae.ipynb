{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f15bfa4b",
   "metadata": {},
   "source": [
    "# VAEGAN: Hybrid VAE-GAN Model\n",
    "\n",
    "This notebook implements a hybrid VAEGAN model that combines:\n",
    "- VAE as generator with 4-layer encoder/decoder\n",
    "- WGAN critic for adversarial training\n",
    "- Modified VAE loss with critic feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9c3464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2310732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(name)s | %(levelname)s | %(message)s'\n",
    ")\n",
    "logger = logging.getLogger('VAEGAN')\n",
    "logger.info(f\"Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf8335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderModule:\n",
    "    \"\"\"Simple dataloader for MNIST and CIFAR10\"\"\"\n",
    "    \n",
    "    def __init__(self, batch_size=64):\n",
    "        self.batch_size = batch_size\n",
    "        self.logger = logging.getLogger('VAEGAN.DataLoader')\n",
    "        \n",
    "    def load_mnist(self):\n",
    "        self.logger.info(\"Loading MNIST dataset\")\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(64),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])  # [-1, 1] range\n",
    "        ])\n",
    "        \n",
    "        dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        self.logger.info(f\"MNIST loaded: {len(dataloader)} batches\")\n",
    "        return dataloader, 1, [64, 64]\n",
    "    \n",
    "    def load_cifar10(self):\n",
    "        self.logger.info(\"Loading CIFAR10 dataset\")\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(64),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # [-1, 1] range\n",
    "        ])\n",
    "        \n",
    "        dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        self.logger.info(f\"CIFAR10 loaded: {len(dataloader)} batches\")\n",
    "        return dataloader, 3, [64, 64]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e185016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEGenerator(nn.Module):\n",
    "    \"\"\"Dynamic VAE with 4-layer encoder and decoder based on latent_dim\"\"\"\n",
    "    \n",
    "    def __init__(self, input_channels=1, latent_dim=128, img_size=64):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_size = img_size\n",
    "        self.logger = logging.getLogger('VAEGAN.VAEGenerator')\n",
    "        \n",
    "        # Dynamic channel sizes based on latent_dim\n",
    "        base_dim = latent_dim // 2  # latent_dim/2\n",
    "        dim2 = latent_dim           # latent_dim\n",
    "        dim3 = latent_dim * 2       # latent_dim*2  \n",
    "        dim4 = latent_dim * 4       # latent_dim*4\n",
    "        \n",
    "        # 4-layer encoder - progressively increase channels\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, base_dim, 4, 2, 1),  # 64x64 -> 32x32\n",
    "            nn.BatchNorm2d(base_dim),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(base_dim, dim2, 4, 2, 1),  # 32x32 -> 16x16\n",
    "            nn.BatchNorm2d(dim2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(dim2, dim3, 4, 2, 1),  # 16x16 -> 8x8\n",
    "            nn.BatchNorm2d(dim3),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(dim3, dim4, 4, 2, 1),  # 8x8 -> 4x4\n",
    "            nn.BatchNorm2d(dim4),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Latent projection\n",
    "        self.fc_mu = nn.Linear(dim4 * 4 * 4, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(dim4 * 4 * 4, latent_dim)\n",
    "        self.fc_decode = nn.Linear(latent_dim, dim4 * 4 * 4)\n",
    "        \n",
    "        # 4-layer decoder - progressively decrease channels\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(dim4, dim3, 4, 2, 1),  # 4x4 -> 8x8\n",
    "            nn.BatchNorm2d(dim3),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(dim3, dim2, 4, 2, 1),  # 8x8 -> 16x16\n",
    "            nn.BatchNorm2d(dim2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(dim2, base_dim, 4, 2, 1),  # 16x16 -> 32x32\n",
    "            nn.BatchNorm2d(base_dim),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(base_dim, input_channels, 4, 2, 1),  # 32x32 -> 64x64\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.logger.info(f\"Dynamic VAE Generator: channels={input_channels}, latent_dim={latent_dim}, dims=[{base_dim}, {dim2}, {dim3}, {dim4}]\")\n",
    "    \n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        h = h.view(h.size(0), -1)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h = self.fc_decode(z)\n",
    "        h = h.view(h.size(0), self.latent_dim * 4, 4, 4)\n",
    "        return self.decoder(h)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decode(z)\n",
    "        return recon, mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36050300",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    \"\"\"Dynamic WGAN-GP Critic with gradient penalty\"\"\"\n",
    "    \n",
    "    def __init__(self, input_channels=1, latent_dim=128):\n",
    "        super().__init__()\n",
    "        self.logger = logging.getLogger('VAEGAN.Critic')\n",
    "        \n",
    "        # Dynamic channel sizes based on latent_dim\n",
    "        base_dim = latent_dim // 2  # latent_dim/2\n",
    "        dim2 = latent_dim           # latent_dim\n",
    "        dim3 = latent_dim * 2       # latent_dim*2\n",
    "        dim4 = latent_dim * 4       # latent_dim*4\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, base_dim, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(base_dim, dim2, 4, 2, 1),\n",
    "            nn.BatchNorm2d(dim2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(dim2, dim3, 4, 2, 1),\n",
    "            nn.BatchNorm2d(dim3),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(dim3, dim4, 4, 2, 1),\n",
    "            nn.BatchNorm2d(dim4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(dim4 * 4 * 4, 1)\n",
    "        self.logger.info(f\"Dynamic Critic: channels={input_channels}, latent_dim={latent_dim}, dims=[{base_dim}, {dim2}, {dim3}, {dim4}]\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.conv_layers(x)\n",
    "        h = h.view(h.size(0), -1)\n",
    "        return self.fc(h).squeeze()\n",
    "    \n",
    "    def gradient_penalty(self, real_images, fake_images, device):\n",
    "        \"\"\"Calculate gradient penalty for WGAN-GP\"\"\"\n",
    "        batch_size = real_images.size(0)\n",
    "        \n",
    "        # Random interpolation weight\n",
    "        alpha = torch.rand(batch_size, 1, 1, 1, device=device)\n",
    "        \n",
    "        # Interpolated images\n",
    "        interpolated = alpha * real_images + (1 - alpha) * fake_images\n",
    "        interpolated.requires_grad_(True)\n",
    "        \n",
    "        # Critic scores for interpolated images\n",
    "        scores = self.forward(interpolated)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=scores,\n",
    "            inputs=interpolated,\n",
    "            grad_outputs=torch.ones_like(scores),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True\n",
    "        )[0]\n",
    "        \n",
    "        # Gradient penalty\n",
    "        gradients = gradients.view(batch_size, -1)\n",
    "        gradient_norm = gradients.norm(2, dim=1)\n",
    "        penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "        \n",
    "        return penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d16b4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEGAN(nn.Module):\n",
    "    \"\"\"Dynamic Hybrid VAEGAN model with VAE generator and WGAN-GP critic\"\"\"\n",
    "    \n",
    "    def __init__(self, input_channels=1, latent_dim=128, img_size=64, lambda_gp=10):\n",
    "        super().__init__()\n",
    "        self.logger = logging.getLogger('VAEGAN.Model')\n",
    "        self.lambda_gp = lambda_gp\n",
    "        \n",
    "        # Dynamic models based on latent_dim\n",
    "        self.generator = VAEGenerator(input_channels, latent_dim, img_size).to(device)\n",
    "        self.critic = Critic(input_channels, latent_dim).to(device)\n",
    "        \n",
    "        self.logger.info(f\"Dynamic VAEGAN initialized: latent_dim={latent_dim}, lambda_gp={lambda_gp}\")\n",
    "    \n",
    "    def vae_loss(self, x, recon, mu, logvar, critic_score):\n",
    "        \"\"\"Modified VAE loss with critic feedback\"\"\"\n",
    "        # Standard VAE losses\n",
    "        recon_loss = F.mse_loss(recon, x, reduction='mean')\n",
    "        kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        \n",
    "        # Adversarial loss - generator wants high critic scores\n",
    "        adv_loss = -torch.mean(critic_score)\n",
    "        \n",
    "        return recon_loss, kl_loss, adv_loss\n",
    "    \n",
    "    def critic_loss(self, real_score, fake_score, gp):\n",
    "        \"\"\"WGAN-GP critic loss with gradient penalty\"\"\"\n",
    "        return torch.mean(fake_score) - torch.mean(real_score) + self.lambda_gp * gp\n",
    "    \n",
    "    def train_step(self, real_images, g_optimizer, c_optimizer, \n",
    "                   recon_weight=1.0, kl_weight=0.1, adv_weight=0.1, critic_iters=5):\n",
    "        batch_size = real_images.size(0)\n",
    "        real_images = real_images.to(device)\n",
    "        \n",
    "        # Train Critic multiple times with gradient penalty\n",
    "        for _ in range(critic_iters):\n",
    "            c_optimizer.zero_grad()\n",
    "            \n",
    "            # Real images\n",
    "            real_score = self.critic(real_images)\n",
    "            \n",
    "            # Fake images from VAE\n",
    "            with torch.no_grad():\n",
    "                fake_images, _, _ = self.generator(real_images)\n",
    "            fake_score = self.critic(fake_images)\n",
    "            \n",
    "            # Gradient penalty\n",
    "            gp = self.critic.gradient_penalty(real_images, fake_images, device)\n",
    "            \n",
    "            c_loss = self.critic_loss(real_score, fake_score, gp)\n",
    "            c_loss.backward()\n",
    "            c_optimizer.step()\n",
    "        \n",
    "        # Train Generator (VAE)\n",
    "        g_optimizer.zero_grad()\n",
    "        \n",
    "        # VAE forward pass\n",
    "        recon, mu, logvar = self.generator(real_images)\n",
    "        \n",
    "        # Get critic score for reconstructed images\n",
    "        critic_score = self.critic(recon)\n",
    "        \n",
    "        # Calculate losses\n",
    "        recon_loss, kl_loss, adv_loss = self.vae_loss(real_images, recon, mu, logvar, critic_score)\n",
    "        \n",
    "        # Combined generator loss\n",
    "        g_loss = recon_weight * recon_loss + kl_weight * kl_loss + adv_weight * adv_loss\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        return {\n",
    "            'g_loss': g_loss.item(),\n",
    "            'c_loss': c_loss.item(),\n",
    "            'recon_loss': recon_loss.item(),\n",
    "            'kl_loss': kl_loss.item(),\n",
    "            'adv_loss': adv_loss.item(),\n",
    "            'gp': gp.item()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8dad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \"\"\"Training loop with visualization\"\"\"\n",
    "    \n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.history = defaultdict(list)\n",
    "        self.logger = logging.getLogger('VAEGAN.Trainer')\n",
    "        \n",
    "    def train(self, dataloader, epochs=10, lr=1e-4):\n",
    "        self.logger.info(f\"Starting training for {epochs} epochs\")\n",
    "        \n",
    "        # Use Adam for both optimizers with WGAN-GP\n",
    "        g_optimizer = optim.Adam(self.model.generator.parameters(), lr=lr, betas=(0.0, 0.9))\n",
    "        c_optimizer = optim.Adam(self.model.critic.parameters(), lr=lr, betas=(0.0, 0.9))\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            epoch_metrics = defaultdict(list)\n",
    "            \n",
    "            for batch_idx, (real_images, _) in enumerate(dataloader):\n",
    "                metrics = self.model.train_step(real_images, g_optimizer, c_optimizer)\n",
    "                \n",
    "                for key, value in metrics.items():\n",
    "                    epoch_metrics[key].append(value)\n",
    "                    self.history[key].append(value)\n",
    "                \n",
    "                if batch_idx % 100 == 0:\n",
    "                    self.logger.info(\n",
    "                        f\"Epoch {epoch} Batch {batch_idx}: \"\n",
    "                        f\"G_loss={metrics['g_loss']:.4f} \"\n",
    "                        f\"C_loss={metrics['c_loss']:.4f} \"\n",
    "                        f\"Recon={metrics['recon_loss']:.4f} \"\n",
    "                        f\"GP={metrics['gp']:.4f}\"\n",
    "                    )\n",
    "            \n",
    "            # Epoch summary\n",
    "            avg_metrics = {k: np.mean(v) for k, v in epoch_metrics.items()}\n",
    "            self.logger.info(\n",
    "                f\"Epoch {epoch} complete: \"\n",
    "                f\"G_loss={avg_metrics['g_loss']:.4f} \"\n",
    "                f\"C_loss={avg_metrics['c_loss']:.4f} \"\n",
    "                f\"Recon={avg_metrics['recon_loss']:.4f} \"\n",
    "                f\"KL={avg_metrics['kl_loss']:.4f} \"\n",
    "                f\"Adv={avg_metrics['adv_loss']:.4f} \"\n",
    "                f\"GP={avg_metrics['gp']:.4f}\"\n",
    "            )\n",
    "            \n",
    "            # Visualize reconstruction after each epoch\n",
    "            self.plot_reconstruction(dataloader, epoch)\n",
    "    \n",
    "    def plot_reconstruction(self, dataloader, epoch):\n",
    "        \"\"\"Plot original vs reconstructed images\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Get sample batch\n",
    "            for real_images, _ in dataloader:\n",
    "                break\n",
    "            \n",
    "            real_images = real_images[:8].to(self.device)\n",
    "            recon_images, _, _ = self.model.generator(real_images)\n",
    "            \n",
    "            # Plot comparison\n",
    "            fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "            \n",
    "            for i in range(8):\n",
    "                # Original\n",
    "                img = real_images[i].cpu()\n",
    "                if img.shape[0] == 1:\n",
    "                    axes[0, i].imshow(img.squeeze(), cmap='gray', vmin=-1, vmax=1)\n",
    "                else:\n",
    "                    img = (img + 1) / 2  # Denormalize\n",
    "                    axes[0, i].imshow(img.permute(1, 2, 0))\n",
    "                axes[0, i].axis('off')\n",
    "                \n",
    "                # Reconstructed\n",
    "                img = recon_images[i].cpu()\n",
    "                if img.shape[0] == 1:\n",
    "                    axes[1, i].imshow(img.squeeze(), cmap='gray', vmin=-1, vmax=1)\n",
    "                else:\n",
    "                    img = (img + 1) / 2  # Denormalize\n",
    "                    axes[1, i].imshow(img.permute(1, 2, 0))\n",
    "                axes[1, i].axis('off')\n",
    "            \n",
    "            axes[0, 0].set_ylabel('Original', fontsize=12)\n",
    "            axes[1, 0].set_ylabel('Reconstructed', fontsize=12)\n",
    "            plt.suptitle(f'Reconstruction Quality - Epoch {epoch}', fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        self.model.train()\n",
    "    \n",
    "    def plot_history(self):\n",
    "        \"\"\"Plot training loss history\"\"\"\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "        \n",
    "        metrics = ['g_loss', 'c_loss', 'recon_loss', 'kl_loss', 'adv_loss', 'gp']\n",
    "        \n",
    "        for i, metric in enumerate(metrics):\n",
    "            if metric in self.history:\n",
    "                row, col = i // 3, i % 3\n",
    "                axes[row, col].plot(self.history[metric])\n",
    "                axes[row, col].set_title(metric.replace('_', ' ').title())\n",
    "                axes[row, col].grid(True)\n",
    "        \n",
    "        # All subplots should be filled now with 6 metrics\n",
    "        \n",
    "        plt.suptitle('Training History', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e59684",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Setup\n",
    "    logger.info(\"Starting VAEGAN training\")\n",
    "    logger.info(\"=\" * 50)\n",
    "    \n",
    "    # Create dataloader\n",
    "    data_loader = DataLoaderModule(batch_size=64)\n",
    "    \n",
    "    # Load MNIST dataset  \n",
    "    dataloader, channels, img_size = data_loader.load_mnist()\n",
    "    \n",
    "    # Create dynamic model with configurable latent_dim for MNIST\n",
    "    latent_dim_mnist = 64  # Smaller for MNIST\n",
    "    model = VAEGAN(input_channels=channels, latent_dim=latent_dim_mnist, img_size=64, lambda_gp=10)\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(model, device)\n",
    "    \n",
    "    # Train model\n",
    "    logger.info(\"Training on MNIST\")\n",
    "    trainer.train(dataloader, epochs=10, lr=1e-4)\n",
    "    \n",
    "    # Plot results\n",
    "    trainer.plot_history()\n",
    "    \n",
    "    logger.info(\"Training completed\")\n",
    "    \n",
    "    # Train on CIFAR10 with larger latent_dim\n",
    "    logger.info(\"Training on CIFAR10\")\n",
    "    dataloader_cifar, channels_cifar, _ = data_loader.load_cifar10()\n",
    "    latent_dim_cifar = 128  # Larger for CIFAR10 (3 channels, more complex)\n",
    "    model_cifar = VAEGAN(input_channels=channels_cifar, latent_dim=latent_dim_cifar, img_size=64, lambda_gp=10)\n",
    "    trainer_cifar = Trainer(model_cifar, device)\n",
    "    trainer_cifar.train(dataloader_cifar, epochs=5, lr=1e-4)\n",
    "    trainer_cifar.plot_history()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
