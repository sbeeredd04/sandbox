{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e85232ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f5177b",
   "metadata": {},
   "source": [
    "## GAN - Discriminator Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "062098cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=128,\n",
    "                 kernel_size=3, stride=2, img_dim=[28, 28], final_size=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Use provided final_size or calculate it\n",
    "        if final_size is None:\n",
    "            # Calculate final spatial dimensions\n",
    "            self.final_height = img_dim[0] // (stride**4)\n",
    "            self.final_width = img_dim[1] // (stride**4)\n",
    "        else:\n",
    "            self.final_height, self.final_width = final_size\n",
    "        \n",
    "        # nn layers\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels * 2, kernel_size=kernel_size, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_channels * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels * 2, out_channels * 4, kernel_size=kernel_size, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_channels * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels * 4, out_channels * 8, kernel_size=kernel_size, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_channels * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(out_channels * 8 * self.final_height * self.final_width, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 4 conv layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        # Flatten the tensor so it can be fed into the FC layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5a55c5",
   "metadata": {},
   "source": [
    "## GAN - Generator Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "944081ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, hidden_dim=64, out_channels=1, img_size=[28, 28], start_size=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_height, self.img_width = img_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Use provided start_size or calculate it\n",
    "        if start_size is None:\n",
    "            # Calculate the starting size after 4 upsampling layers\n",
    "            self.start_height = self.img_height // (2**4)\n",
    "            self.start_width = self.img_width // (2**4)\n",
    "        else:\n",
    "            self.start_height, self.start_width = start_size\n",
    "        \n",
    "        # Linear layer to project noise to initial feature maps\n",
    "        self.linear = nn.Linear(latent_dim, hidden_dim * 8 * self.start_height * self.start_width)\n",
    "        \n",
    "        # Upsampling layers (reverse of discriminator)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(hidden_dim * 8, hidden_dim * 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(hidden_dim * 4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(hidden_dim * 2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(hidden_dim * 2, hidden_dim, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(hidden_dim, out_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()  # Output values between -1 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Project noise to initial feature maps\n",
    "        x = self.linear(x)\n",
    "        x = x.view(x.size(0), self.hidden_dim * 8, self.start_height, self.start_width)\n",
    "        \n",
    "        # Upsampling layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2479e2b",
   "metadata": {},
   "source": [
    "## GAN Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346db295",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, latent_dim=100, img_size=[28, 28], channels=1, \n",
    "                 hidden_dim=64, out_channels=128, kernel_size=3, stride=2,\n",
    "                 batch_size=128, lr=0.0002, device=None):\n",
    "        \n",
    "        # Set device\n",
    "        self.device = device if device else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Parameters\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_size = img_size\n",
    "        self.channels = channels\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        \n",
    "        # Calculate dimensions dynamically\n",
    "        self.discriminator_final_size = self._calculate_discriminator_final_size(img_size, kernel_size, stride)\n",
    "        \n",
    "        # Initialize networks with calculated dimensions\n",
    "        self.generator = Generator(\n",
    "            latent_dim=latent_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            out_channels=channels,\n",
    "            img_size=img_size,\n",
    "            start_size=self.discriminator_final_size  # Pass calculated start size\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.discriminator = Discriminator(\n",
    "            in_channels=channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            img_dim=img_size,\n",
    "            final_size=self.discriminator_final_size  # Pass calculated final size\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.generator.apply(self.init_weights)\n",
    "        self.discriminator.apply(self.init_weights)\n",
    "        \n",
    "        # Loss function\n",
    "        self.loss = nn.BCELoss()\n",
    "        \n",
    "        # Optimizers\n",
    "        self.g_optimizer = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "        self.d_optimizer = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "        \n",
    "        # Random noise for validation\n",
    "        self.validation_z = torch.randn(batch_size, latent_dim, device=self.device)\n",
    "    \n",
    "    def _calculate_discriminator_final_size(self, img_size, kernel_size, stride, num_layers=4):\n",
    "        h, w = img_size\n",
    "        padding = 1  # Assuming padding=1 for all conv layers\n",
    "        \n",
    "        for _ in range(num_layers):\n",
    "            # Convolution output size formula: (input + 2*padding - kernel) / stride + 1\n",
    "            h = (h + 2*padding - kernel_size) // stride + 1\n",
    "            w = (w + 2*padding - kernel_size) // stride + 1\n",
    "        \n",
    "        return [h, w]\n",
    "    \n",
    "    def _calculate_generator_start_size(self, img_size, kernel_size, stride, num_layers=4):\n",
    "        return self._calculate_discriminator_final_size(img_size, kernel_size, stride, num_layers)\n",
    "    \n",
    "    def get_network_info(self):\n",
    "        disc_final = self.discriminator_final_size\n",
    "        gen_start = self._calculate_generator_start_size(self.img_size, self.kernel_size, self.stride)\n",
    "        \n",
    "        return {\n",
    "            'input_size': self.img_size,\n",
    "            'discriminator_final_size': disc_final,\n",
    "            'generator_start_size': gen_start,\n",
    "            'channels': self.channels,\n",
    "            'latent_dim': self.latent_dim,\n",
    "            'hidden_dim': getattr(self.generator, 'hidden_dim', 'N/A'),\n",
    "            'out_channels': getattr(self.discriminator, 'out_channels', 'N/A')\n",
    "        }\n",
    "    \n",
    "    def init_weights(self, m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1 or classname.find('BatchNorm') != -1:\n",
    "            m.weight.data.normal_(0.00, 0.02)\n",
    "    \n",
    "    def noise(self, size):\n",
    "        return torch.randn(size, self.latent_dim, device=self.device)\n",
    "    \n",
    "    def real_data_target(self, size):\n",
    "        return torch.ones(size, 1, device=self.device)\n",
    "    \n",
    "    def fake_data_target(self, size):\n",
    "        return torch.zeros(size, 1, device=self.device)\n",
    "    \n",
    "    def train_discriminator(self, real_data, fake_data):\n",
    "        # Reset gradients\n",
    "        self.d_optimizer.zero_grad()\n",
    "        \n",
    "        # Train on Real Data\n",
    "        prediction_real = self.discriminator(real_data)\n",
    "        error_real = self.loss(prediction_real, self.real_data_target(real_data.size(0)))\n",
    "        error_real.backward()\n",
    "\n",
    "        # Train on Fake Data\n",
    "        prediction_fake = self.discriminator(fake_data)\n",
    "        error_fake = self.loss(prediction_fake, self.fake_data_target(real_data.size(0)))\n",
    "        error_fake.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        self.d_optimizer.step()\n",
    "        \n",
    "        return error_real + error_fake, prediction_real, prediction_fake\n",
    "\n",
    "    def train_generator(self, fake_data):\n",
    "        # Reset gradients\n",
    "        self.g_optimizer.zero_grad()\n",
    "        \n",
    "        # Sample noise and generate fake data\n",
    "        prediction = self.discriminator(fake_data)\n",
    "        error = self.loss(prediction, self.real_data_target(prediction.size(0)))\n",
    "        error.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        self.g_optimizer.step()\n",
    "        \n",
    "        return error\n",
    "    \n",
    "    def train_step(self, real_imgs):\n",
    "        # Generate fake data for discriminator training\n",
    "        fake_data = self.generator(self.noise(real_imgs.size(0))).detach()\n",
    "        \n",
    "        # 1. Train Discriminator\n",
    "        d_error, d_pred_real, d_pred_fake = self.train_discriminator(real_imgs, fake_data)\n",
    "        \n",
    "        # 2. Train Generator\n",
    "        fake_data = self.generator(self.noise(real_imgs.size(0)))\n",
    "        g_error = self.train_generator(fake_data)\n",
    "        \n",
    "        return {\n",
    "            \"d_loss\": d_error.item(),\n",
    "            \"g_loss\": g_error.item(),\n",
    "            \"d_pred_real\": d_pred_real.mean().item(),\n",
    "            \"d_pred_fake\": d_pred_fake.mean().item()\n",
    "        }\n",
    "    \n",
    "    def generate_samples(self, num_samples=16):\n",
    "        \"\"\"Generate sample images\"\"\"\n",
    "        with torch.no_grad():\n",
    "            noise = self.noise(num_samples)\n",
    "            samples = self.generator(noise)\n",
    "            return samples.cpu().detach()\n",
    "    \n",
    "    def plot_samples(self, num_samples=16):\n",
    "        \"\"\"Plot generated samples\"\"\"\n",
    "        samples = self.generate_samples(num_samples)\n",
    "        \n",
    "        fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
    "        for i in range(min(16, num_samples)):\n",
    "            row, col = i // 4, i % 4\n",
    "            axes[row, col].imshow(samples[i].squeeze().numpy(), cmap='gray')\n",
    "            axes[row, col].axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def save_models(self, path):\n",
    "        \"\"\"Save generator and discriminator\"\"\"\n",
    "        torch.save({\n",
    "            'generator_state_dict': self.generator.state_dict(),\n",
    "            'discriminator_state_dict': self.discriminator.state_dict(),\n",
    "            'g_optimizer_state_dict': self.g_optimizer.state_dict(),\n",
    "            'd_optimizer_state_dict': self.d_optimizer.state_dict(),\n",
    "            'network_info': self.get_network_info(),  # Save network configuration\n",
    "        }, path)\n",
    "    \n",
    "    def load_models(self, path):\n",
    "        \"\"\"Load generator and discriminator\"\"\"\n",
    "        checkpoint = torch.load(path, map_location=self.device)\n",
    "        self.generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "        self.discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n",
    "        self.g_optimizer.load_state_dict(checkpoint['g_optimizer_state_dict'])\n",
    "        self.d_optimizer.load_state_dict(checkpoint['d_optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223a7c78",
   "metadata": {},
   "source": [
    "## DataLoader Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2470981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self, data_dir=\"./data\", batch_size=128, num_workers=1):\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "    def load_mnist(self, split_ratio=0.9):\n",
    "\n",
    "        # MNIST transforms\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        ])\n",
    "        \n",
    "        # Download and load datasets\n",
    "        mnist_train = MNIST(self.data_dir, train=True, download=True, transform=transform)\n",
    "        mnist_test = MNIST(self.data_dir, train=False, download=True, transform=transform)\n",
    "        \n",
    "        # Split training data into train and validation\n",
    "        train_size = int(split_ratio * len(mnist_train))\n",
    "        val_size = len(mnist_train) - train_size\n",
    "        train_dataset, val_dataset = random_split(mnist_train, [train_size, val_size])\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=True, \n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=False, \n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "        \n",
    "        test_loader = DataLoader(\n",
    "            mnist_test, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=False, \n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "        \n",
    "        # MNIST specifications\n",
    "        img_size = [28, 28]\n",
    "        channels = 1\n",
    "        \n",
    "        return train_loader, val_loader, test_loader, img_size, channels\n",
    "    \n",
    "    def load_cifar10(self, split_ratio=0.9):\n",
    "\n",
    "        # CIFAR10 transforms\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "        \n",
    "        # Download and load datasets\n",
    "        cifar_train = CIFAR10(self.data_dir, train=True, download=True, transform=transform)\n",
    "        cifar_test = CIFAR10(self.data_dir, train=False, download=True, transform=transform)\n",
    "        \n",
    "        # Split training data into train and validation\n",
    "        train_size = int(split_ratio * len(cifar_train))\n",
    "        val_size = len(cifar_train) - train_size\n",
    "        train_dataset, val_dataset = random_split(cifar_train, [train_size, val_size])\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=True, \n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=False, \n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "        \n",
    "        test_loader = DataLoader(\n",
    "            cifar_test, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=False, \n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "        \n",
    "        # CIFAR10 specifications\n",
    "        img_size = [32, 32]\n",
    "        channels = 3\n",
    "        \n",
    "        return train_loader, val_loader, test_loader, img_size, channels\n",
    "    \n",
    "    def get_dataset_info(self, dataset_name):\n",
    "        if dataset_name.lower() == 'mnist':\n",
    "            return {\n",
    "                'img_size': [28, 28],\n",
    "                'channels': 1,\n",
    "                'num_classes': 10,\n",
    "                'name': 'MNIST'\n",
    "            }\n",
    "        elif dataset_name.lower() == 'cifar10':\n",
    "            return {\n",
    "                'img_size': [32, 32],\n",
    "                'channels': 3,\n",
    "                'num_classes': 10,\n",
    "                'name': 'CIFAR10'\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown dataset: {dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c180cef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] Batch [0/422] D_loss: 1.3874 G_loss: 0.7240\n",
      "Epoch [0/50] Batch [100/422] D_loss: 0.1167 G_loss: 2.8624\n"
     ]
    }
   ],
   "source": [
    "# Initialize dataset class\n",
    "dataset = DataSet(batch_size=128, num_workers=2)\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_loader, val_loader, test_loader, img_size, channels = dataset.load_mnist()\n",
    "\n",
    "# Initialize GAN with MNIST specifications\n",
    "gan_mnist = GAN(\n",
    "    latent_dim=100,\n",
    "    img_size=img_size,\n",
    "    channels=channels,\n",
    "    hidden_dim=64,\n",
    "    out_channels=128,\n",
    "    kernel_size=3,\n",
    "    stride=2,\n",
    "    batch_size=128,\n",
    "    lr=0.0002\n",
    ")\n",
    "\n",
    "# # Load CIFAR10 dataset\n",
    "# train_loader, val_loader, test_loader, img_size, channels = dataset.load_cifar10()\n",
    "\n",
    "# # Initialize GAN with CIFAR10 specifications\n",
    "# gan_cifar = GAN(\n",
    "#     latent_dim=100,\n",
    "#     img_size=img_size,\n",
    "#     channels=channels,\n",
    "#     hidden_dim=64,\n",
    "#     out_channels=128,\n",
    "#     kernel_size=3,\n",
    "#     stride=2,\n",
    "#     batch_size=128,\n",
    "#     lr=0.0002\n",
    "# )\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real_imgs, _) in enumerate(train_loader):\n",
    "        real_imgs = real_imgs.to(gan_mnist.device)\n",
    "        \n",
    "        # Train step\n",
    "        losses = gan_mnist.train_step(real_imgs)\n",
    "        \n",
    "        # Log progress\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}] Batch [{batch_idx}/{len(train_loader)}] \"\n",
    "                  f\"D_loss: {losses['d_loss']:.4f} G_loss: {losses['g_loss']:.4f}\")\n",
    "    \n",
    "    # Plot samples every few epochs\n",
    "    if epoch % 10 == 0:\n",
    "        gan_mnist.plot_samples()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
